{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjectCodeIDK.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "zg_I2qdg7l4n",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def DataLoad(ID,name):\n",
        "  # Code to read csv file into colaboratory:\n",
        "  !pip install -U -q PyDrive\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "\n",
        "  # 1. Authenticate and create the PyDrive client.\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "\n",
        "  #2. Get the file\n",
        "  downloaded = drive.CreateFile({'id':ID}) # replace the id with id of file you want to access\n",
        "  downloaded.GetContentFile(name)  \n",
        "\n",
        "  #3. Read file as panda dataframe\n",
        "  import pandas as pd\n",
        "  DATA = pd.read_csv(name)\n",
        "  DATA = DATA.values\n",
        "  return DATA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kBUqTo6HWZO3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 61
            },
            {
              "item_id": 109
            },
            {
              "item_id": 206
            },
            {
              "item_id": 267
            },
            {
              "item_id": 297
            },
            {
              "item_id": 325
            },
            {
              "item_id": 355
            },
            {
              "item_id": 384
            },
            {
              "item_id": 414
            },
            {
              "item_id": 445
            },
            {
              "item_id": 453
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1266
        },
        "outputId": "200b6586-0c7d-4c5c-8ec6-d34dc1093d30",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1519424043457,
          "user_tz": 480,
          "elapsed": 309949,
          "user": {
            "displayName": "Michael Thompson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110817915921754086116"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "## Load Data\n",
        "Obama1_ID_X = '1j8xblrjXOuAy2S_v4Qlo_hPJ4BWSUME5'\n",
        "Obama1_name_X = 'obama1_X.csv'\n",
        "Obama1_ID_Y = '1e8LfCcNRDJkzOaQKBO9HHNqU4DV_DPCh'\n",
        "Obama1_name_Y = 'obama1_Y.csv'\n",
        "Trump1_ID_X ='1Xtp9-M76UjcHnqTYpeawUM6zLHznrp-B'\n",
        "Trump1_name_X = 'trump1_X.csv'\n",
        "Trump1_ID_Y ='1mVVuBg3HKsJ2qX-nu_sq8bAjNZhsxUfm'\n",
        "Trump1_name_Y = 'trump1_Y.csv'\n",
        "trainPercent = 0.95 # % of samples to train on\n",
        "\n",
        "Obama1_X_DATASET = DataLoad(Obama1_ID_X,Obama1_name_X)\n",
        "Obama1_Y_DATASET = DataLoad(Obama1_ID_Y,Obama1_name_Y)\n",
        "Trump1_X_DATASET = DataLoad(Trump1_ID_X,Trump1_name_X)\n",
        "Trump1_Y_DATASET = DataLoad(Trump1_ID_Y,Trump1_name_Y)\n",
        "X_DATASET=np.vstack((Obama1_X_DATASET,Trump1_X_DATASET))\n",
        "Y_DATASET=np.vstack((Obama1_Y_DATASET,Trump1_Y_DATASET))\n",
        "DATASET = np.hstack((X_DATASET,Y_DATASET))\n",
        "np.random.shuffle(DATASET)\n",
        "X_DATASET = DATASET[:,0:X_DATASET.shape[1]]\n",
        "Y_DATASET = DATASET[:,X_DATASET.shape[1]:DATASET.shape[1]]\n",
        "\n",
        "mtrain = int(trainPercent*X_DATASET.shape[0])\n",
        "x_train = X_DATASET[0:mtrain,0:X_DATASET.shape[1]]\n",
        "x_test  = X_DATASET[mtrain:X_DATASET.shape[0],0:X_DATASET.shape[1]]\n",
        "y_train = Y_DATASET[0:mtrain,0:Y_DATASET.shape[1]]\n",
        "y_test  = Y_DATASET[mtrain:Y_DATASET.shape[0],0:Y_DATASET.shape[1]]\n",
        "\n",
        "classes = y_train.shape[1]  # num speakers\n",
        "n_vec =   x_train.shape[1]  # length of feature vector\n",
        "m_train = x_train.shape[0]  # num training examples\n",
        "m_test =  x_test.shape[0]   # num test examples\n",
        "params = {}                 # initalize params\n",
        "\n",
        "print (\"number of training examples = \" + str(m_train))\n",
        "print (\"number of test examples = \" + str(m_test))\n",
        "print(\"number of classes: \" + str(classes))\n",
        "print (\"X_train shape: \" + str(x_train.shape))\n",
        "print (\"Y_train shape: \" + str(y_train.shape))\n",
        "print (\"X_test shape: \" + str(x_test.shape))\n",
        "print (\"Y_test shape: \" + str(y_test.shape))\n",
        "\n",
        "#################### Hyperparameters ####################\n",
        "L = 5                                   # num layers in network\n",
        "bsize = 32                              # minibatch size\n",
        "epochnum = 20                           # num epochs for optimization\n",
        "learning_rate = 0.001                   # params for Adam\n",
        "learning_decay = 0.00001                # learning decay for Adam\n",
        "BN_mom = 0.99                           # momentum for batch norm\n",
        "L2 = np.array([.1,.1,.1,.1,.1])         # L2 lambda parameters for each layer\n",
        "N = np.array([390,390,390,390,classes]) # num nodes/layer for each hidden layer\n",
        "#########################################################\n",
        "\n",
        "\n",
        "for l in range(1,L+1):\n",
        "    params[\"L2_\"+str(l)] = L2[l-1]\n",
        "    params[\"N\"+str(l)] = N[l-1]\n",
        "\n",
        "## NN Model (X->RELU->RELU->RELU->RELU->SOFTMAX)\n",
        "model = Sequential()\n",
        "model.add(Dense(params['N1'], activation='relu', input_dim=n_vec,use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=regularizers.l2(params[\"L2_1\"]), bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None,name='fc1'))\n",
        "model.add(BatchNormalization(axis=1, momentum=BN_mom, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones',name='bn1'))\n",
        "for l in range(2,L-1):\n",
        "    model.add(Dense(params['N'+str(l)], activation='relu',use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=regularizers.l2(params[\"L2_\" + str(l)]), bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None,name='fc'+str(l)))\n",
        "    model.add(BatchNormalization(axis=1, momentum=BN_mom, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones',name='bn'+str(l)))\n",
        "model.add(Dense(params['N'+str(L)], activation='softmax',use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=regularizers.l2(params[\"L2_\" + str(L)]), bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None,name='fc'+str(L)))\n",
        "\n",
        "## Compile and Train Model\n",
        "adam_opt = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=learning_decay, amsgrad=False)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=adam_opt,metrics=['accuracy'])\n",
        "model.fit(x_train, y_train,epochs=epochnum,batch_size=bsize)\n",
        "\n",
        "## Test Model\n",
        "preds = model.evaluate(x_test, y_test, batch_size=bsize)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))\n",
        "\n",
        "## Model Predictions of Test Set\n",
        "y_hat = model.predict(x_test, batch_size=bsize)\n",
        "\n",
        "## Display Model Architecture\n",
        "model.summary()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training examples = 41466\n",
            "number of test examples = 2183\n",
            "number of classes: 2\n",
            "X_train shape: (41466, 13)\n",
            "Y_train shape: (41466, 2)\n",
            "X_test shape: (2183, 13)\n",
            "Y_test shape: (2183, 2)\n",
            "Epoch 1/20\n",
            "41466/41466 [==============================] - 16s 377us/step - loss: 2.8671 - acc: 0.8519\n",
            "Epoch 2/20\n",
            " 8960/41466 [=====>........................] - ETA: 11s - loss: 0.4530 - acc: 0.8632"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "41466/41466 [==============================] - 15s 364us/step - loss: 0.4446 - acc: 0.8630\n",
            "Epoch 3/20\n",
            "41466/41466 [==============================] - 15s 363us/step - loss: 0.4052 - acc: 0.8673\n",
            "Epoch 4/20\n",
            "17472/41466 [===========>..................] - ETA: 8s - loss: 0.3776 - acc: 0.8723"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "41466/41466 [==============================] - 15s 361us/step - loss: 0.3698 - acc: 0.8715\n",
            "Epoch 5/20\n",
            "41466/41466 [==============================] - 15s 363us/step - loss: 0.3502 - acc: 0.8746\n",
            "Epoch 6/20\n",
            "20032/41466 [=============>................] - ETA: 7s - loss: 0.3390 - acc: 0.8779"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "41466/41466 [==============================] - 15s 361us/step - loss: 0.3370 - acc: 0.8771\n",
            "Epoch 7/20\n",
            "41466/41466 [==============================] - 15s 362us/step - loss: 0.3330 - acc: 0.8776\n",
            "Epoch 8/20\n",
            "20928/41466 [==============>...............] - ETA: 7s - loss: 0.3330 - acc: 0.8781"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "41466/41466 [==============================] - 15s 357us/step - loss: 0.3283 - acc: 0.8785\n",
            "Epoch 9/20\n",
            "41466/41466 [==============================] - 15s 361us/step - loss: 0.3235 - acc: 0.8812\n",
            "Epoch 10/20\n",
            "20928/41466 [==============>...............] - ETA: 7s - loss: 0.3239 - acc: 0.8796"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "41466/41466 [==============================] - 15s 357us/step - loss: 0.3245 - acc: 0.8794\n",
            "Epoch 11/20\n",
            "41466/41466 [==============================] - 15s 360us/step - loss: 0.3226 - acc: 0.8795\n",
            "Epoch 12/20\n",
            "20800/41466 [==============>...............] - ETA: 7s - loss: 0.3308 - acc: 0.8767"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "41466/41466 [==============================] - 15s 359us/step - loss: 0.3275 - acc: 0.8774\n",
            "Epoch 13/20\n",
            "41466/41466 [==============================] - 15s 360us/step - loss: 0.3209 - acc: 0.8804\n",
            "Epoch 14/20\n",
            "20960/41466 [==============>...............] - ETA: 7s - loss: 0.3182 - acc: 0.8802"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "41466/41466 [==============================] - 15s 359us/step - loss: 0.3199 - acc: 0.8786\n",
            "Epoch 15/20\n",
            "41466/41466 [==============================] - 15s 356us/step - loss: 0.3187 - acc: 0.8806\n",
            "Epoch 16/20\n",
            "20960/41466 [==============>...............] - ETA: 7s - loss: 0.3221 - acc: 0.8782"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "41466/41466 [==============================] - 15s 356us/step - loss: 0.3175 - acc: 0.8815\n",
            "Epoch 17/20\n",
            "41466/41466 [==============================] - 15s 358us/step - loss: 0.3159 - acc: 0.8812\n",
            "Epoch 18/20\n",
            "20928/41466 [==============>...............] - ETA: 7s - loss: 0.3191 - acc: 0.8761"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "41466/41466 [==============================] - 15s 356us/step - loss: 0.3163 - acc: 0.8790\n",
            "Epoch 19/20\n",
            "41466/41466 [==============================] - 15s 356us/step - loss: 0.3137 - acc: 0.8819\n",
            "Epoch 20/20\n",
            "21184/41466 [==============>...............] - ETA: 7s - loss: 0.3160 - acc: 0.8782"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "41466/41466 [==============================] - 15s 356us/step - loss: 0.3159 - acc: 0.8806\n",
            "2183/2183 [==============================] - 0s 128us/step\n",
            "Loss = 0.30753354559619656\n",
            "Test Accuracy = 0.8818140174345418\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "fc1 (Dense)                  (None, 390)               5460      \n",
            "_________________________________________________________________\n",
            "bn1 (BatchNormalization)     (None, 390)               1560      \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 390)               152490    \n",
            "_________________________________________________________________\n",
            "bn2 (BatchNormalization)     (None, 390)               1560      \n",
            "_________________________________________________________________\n",
            "fc3 (Dense)                  (None, 390)               152490    \n",
            "_________________________________________________________________\n",
            "bn3 (BatchNormalization)     (None, 390)               1560      \n",
            "_________________________________________________________________\n",
            "fc5 (Dense)                  (None, 2)                 782       \n",
            "=================================================================\n",
            "Total params: 315,902\n",
            "Trainable params: 313,562\n",
            "Non-trainable params: 2,340\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BTHq4Elkth6X",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}