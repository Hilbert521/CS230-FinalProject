{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1347,
     "output_extras": [
      {
       "item_id": 15
      },
      {
       "item_id": 43
      },
      {
       "item_id": 72
      },
      {
       "item_id": 101
      },
      {
       "item_id": 126
      },
      {
       "item_id": 167
      },
      {
       "item_id": 208
      },
      {
       "item_id": 246
      },
      {
       "item_id": 276
      },
      {
       "item_id": 301
      },
      {
       "item_id": 316
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 259308,
     "status": "ok",
     "timestamp": 1519418932673,
     "user": {
      "displayName": "David Troner",
      "photoUrl": "//lh6.googleusercontent.com/-Qsk0YFyokns/AAAAAAAAAAI/AAAAAAAAAA8/SH9fYhiAFZ0/s50-c-k-no/photo.jpg",
      "userId": "113969831701106809941"
     },
     "user_tz": 480
    },
    "id": "kBUqTo6HWZO3",
    "outputId": "2bd196c1-f4c7-48a8-eb67-87d1fd4095dc"
   },
   "outputs": [],
   "source": [
    "def VoiceIDnet(x_train,y_train,x_test,y_test,X0):\n",
    "\n",
    "    !pip install -q keras\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Activation, BatchNormalization\n",
    "    from keras.optimizers import SGD\n",
    "    from keras import regularizers, optimizers\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "\n",
    "    classes = y_train.shape[1]  # num speakers\n",
    "    n_vec =   x_train.shape[1]  # length of feature vector\n",
    "    m_train = x_train.shape[0]  # num training examples\n",
    "    m_test =  x_test.shape[0]   # num test examples\n",
    "    params = {}                 # initalize params\n",
    "\n",
    "    print (\"number of training examples = \" + str(m_train))\n",
    "    print (\"number of test examples = \" + str(m_test))\n",
    "    print(\"number of classes: \" + str(classes))\n",
    "\n",
    "    Lparam     = int(X0[0])\n",
    "    bsizeparam = int(X0[1])\n",
    "    L2param    = int(X0[2]*1000)/1000\n",
    "    Nparam     = int(X0[3])\n",
    "  \n",
    "    #################### Hyperparameters ####################\n",
    "    L = Lparam                       # num layers in network\n",
    "    bsize = bsizeparam               # minibatch size\n",
    "    epochnum = 20                    # num epochs for optimization\n",
    "    learning_rate = 0.001            # params for Adam\n",
    "    learning_decay = 0.00001         # learning decay for Adam\n",
    "    BN_mom = 0.99                    # momentum for batch norm\n",
    "    L2 = np.ones(L)*L2param          # L2 lambda parameters for each layer\n",
    "    N = np.append(np.ones(L-1)*Nparam,classes)   # num nodes/layer for each hidden layer\n",
    "    #########################################################\n",
    "    \n",
    "\n",
    "    for l in range(1,L+1):\n",
    "        params[\"L2_\"+str(l)] = L2[l-1]\n",
    "        params[\"N\"+str(l)] = N[l-1]\n",
    "\n",
    "    ## NN Model (X->RELU->RELU->RELU->RELU->SOFTMAX)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['N1'], activation='relu', input_dim=n_vec,use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=regularizers.l2(params[\"L2_1\"]), bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None,name='fc1'))\n",
    "    model.add(BatchNormalization(axis=1, momentum=BN_mom, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones',name='bn1'))\n",
    "    for l in range(2,L-1):\n",
    "        model.add(Dense(params['N'+str(l)], activation='relu',use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=regularizers.l2(params[\"L2_\" + str(l)]), bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None,name='fc'+str(l)))\n",
    "        model.add(BatchNormalization(axis=1, momentum=BN_mom, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones',name='bn'+str(l)))\n",
    "    model.add(Dense(params['N'+str(L)], activation='softmax',use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=regularizers.l2(params[\"L2_\" + str(L)]), bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None,name='fc'+str(L)))\n",
    "\n",
    "    ## Compile and Train Model\n",
    "    adam_opt = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=learning_decay, amsgrad=False)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=adam_opt,metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,epochs=epochnum,batch_size=bsize)\n",
    "\n",
    "    ## Test Model\n",
    "    preds = model.evaluate(x_test, y_test, batch_size=bsize)\n",
    "    test_accuracy = preds[1]\n",
    "    test_loss = preds[0]\n",
    "    print (\"Loss = \" + str(test_loss))\n",
    "    print (\"Test Accuracy = \" + str(test_accuracy))\n",
    "\n",
    "    ## Model Predictions of Test Set\n",
    "    y_hat = model.predict(x_test, batch_size=bsize)\n",
    "\n",
    "    ## Display Model Architecture\n",
    "    model.summary()\n",
    "    \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vd74nlg5aCWW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "ProjectCodeIDK.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
