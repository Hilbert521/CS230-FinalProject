{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1347,
     "output_extras": [
      {
       "item_id": 15
      },
      {
       "item_id": 43
      },
      {
       "item_id": 72
      },
      {
       "item_id": 101
      },
      {
       "item_id": 126
      },
      {
       "item_id": 167
      },
      {
       "item_id": 208
      },
      {
       "item_id": 246
      },
      {
       "item_id": 276
      },
      {
       "item_id": 301
      },
      {
       "item_id": 316
      }
     ]
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 259308,
     "status": "ok",
     "timestamp": 1519418932673,
     "user": {
      "displayName": "David Troner",
      "photoUrl": "//lh6.googleusercontent.com/-Qsk0YFyokns/AAAAAAAAAAI/AAAAAAAAAA8/SH9fYhiAFZ0/s50-c-k-no/photo.jpg",
      "userId": "113969831701106809941"
     },
     "user_tz": 480
    },
    "id": "kBUqTo6HWZO3",
    "outputId": "2bd196c1-f4c7-48a8-eb67-87d1fd4095dc"
   },
   "outputs": [],
   "source": [
    "def LoadDATA(dev_flag=1):\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    filestr = os.getcwd()+'\\\\..\\\\Data\\\\MFCC_Data\\\\'\n",
    "    Xtrain = filestr+'X_train.csv'  \n",
    "    Ytrain = filestr+'Y_train.csv'  \n",
    "    Xdev = filestr+'X_dev.csv'\n",
    "    Ydev = filestr+'Y_dev.csv'  \n",
    "    Xtest = filestr+'X_test.csv'\n",
    "    Ytest = filestr+'Y_test.csv' \n",
    "    \n",
    "    x_train = pd.read_csv(Xtrain).values\n",
    "    y_train = pd.read_csv(Xtrain).values\n",
    "    if dev_flag == 1:  \n",
    "        x_test = pd.read_csv(Xdev).values\n",
    "        y_test = pd.read_csv(Ydev).values\n",
    "    else:\n",
    "        x_test = pd.read_csv(Xtest).values\n",
    "        y_test = pd.read_csv(Ytest).values \n",
    "  \n",
    "    return x_train,x_test,y_train,y_test\n",
    "\n",
    "\n",
    "def NNcode(x):\n",
    "    !pip install -q keras\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Activation, BatchNormalization\n",
    "    from keras.optimizers import SGD\n",
    "    from keras import regularizers, optimizers\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "\n",
    "    Lparam     = int(x[0])\n",
    "    bsizeparam = int(x[1])\n",
    "    L2param    = int(x[2])/100\n",
    "    Nparam     = int(x[3])\n",
    "  \n",
    "    #################### Hyperparameters ####################\n",
    "    show_plots = 1                   # Bool, to show training plots\n",
    "    L = Lparam                       # num layers in network\n",
    "    bsize = bsizeparam               # minibatch size\n",
    "    epochnum = 10                    # num epochs for optimization\n",
    "    learning_rate = 0.001            # params for Adam\n",
    "    learning_decay = 0.00001         # learning decay for Adam\n",
    "    BN_mom = 0.99                    # momentum for batch norm\n",
    "    L2 = np.ones(L)*L2param          # L2 lambda parameters for each layer\n",
    "    N = np.append(np.ones(L-1)*Nparam,classes)   # num nodes/layer for each hidden layer\n",
    "    #########################################################\n",
    "    params = {}\n",
    "  \n",
    "    for l in range(1,L+1):\n",
    "        params[\"L2_\"+str(l)] = int(L2[l-1]*100)/100\n",
    "        params[\"N\"+str(l)] = int(N[l-1])\n",
    "\n",
    "    ## NN Model (X->RELU->RELU->RELU->RELU->SOFTMAX)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['N1'], activation='relu', input_dim=n_vec,use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=regularizers.l2(params[\"L2_1\"]), bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None,name='fc1'))\n",
    "    model.add(BatchNormalization(axis=1, momentum=BN_mom, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones',name='bn1'))\n",
    "    for l in range(2,L-1):\n",
    "        model.add(Dense(params['N'+str(l)], activation='relu',use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=regularizers.l2(params[\"L2_\" + str(l)]), bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None,name='fc'+str(l)))\n",
    "        model.add(BatchNormalization(axis=1, momentum=BN_mom, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones',name='bn'+str(l)))\n",
    "    model.add(Dense(params['N'+str(L)], activation='softmax',use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=regularizers.l2(params[\"L2_\" + str(L)]), bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None,name='fc'+str(L)))\n",
    "  \n",
    "  \n",
    "    ## Compile and Train Model\n",
    "    adam_opt = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=learning_decay, amsgrad=False)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=adam_opt,metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train,batch_size=bsize,epochs=epochnum,verbose=0)\n",
    "  \n",
    "      ## Plots\n",
    "    if show_plots == 1:\n",
    "        import matplotlib.pyplot as plt\n",
    "        #  \"Accuracy\"\n",
    "        plt.plot(history.history['acc'])\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.show()\n",
    "        # \"Loss\"\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.show()\n",
    "  \n",
    "    ## Test Model\n",
    "    preds = model.evaluate(x_test, y_test, batch_size=bsize)\n",
    "    print (\"Loss = \" + str(preds[0]))\n",
    "    print (\"Test Accuracy = \" + str(preds[1]))\n",
    "    print(\"with X = \" + str(x.T))\n",
    "  \n",
    "\n",
    "    ## Model Predictions of Test Set\n",
    "    y_hat = model.predict(x_test, batch_size=bsize)\n",
    "    return preds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "vd74nlg5aCWW",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grid Search over Hyperparameters\n",
    "import numpy as np\n",
    "x_train,x_test,y_train,y_test = LoadDATA(1)\n",
    "classes = y_train.shape[1]  # num speakers\n",
    "n_vec =   x_train.shape[1]  # length of feature vector\n",
    "m_train = x_train.shape[0]  # num training examples\n",
    "m_test =  x_test.shape[0]   # num test examples\n",
    "\n",
    "L_list = [5]#[5,7,10,15,20]\n",
    "Bsize_list = [16]#[16,32,64,128,256]\n",
    "L2_list = [.1]#[.1,.2,.3,.4,.5]\n",
    "N_list = [390]#[10,20,50,100,390,500,1000]\n",
    "\n",
    "len1 = len(L_list)\n",
    "len2 = len(Bsize_list)\n",
    "len3 = len(L2_list)\n",
    "len4 = len(N_list)\n",
    "len_total = len1*len2*len3*len4\n",
    "count = 0\n",
    "x = np.zeros((4,1))\n",
    "params = np.zeros((len_total,4))\n",
    "test_acc = np.zeros((len_total,1))\n",
    "\n",
    "for i1 in range(len1):\n",
    "    for i2 in range(len2):\n",
    "        for i3 in range(len3):\n",
    "            for i4 in range(len4):\n",
    "                x[0] = L_list[i1]\n",
    "                x[1] = Bsize_list[i2]\n",
    "                x[2] = L2_list[i3]\n",
    "                x[3] = N_list[i4]\n",
    "                test_acc[count] = NNcode(x)\n",
    "                params[count,:] = np.array([x[0],x[1],x[2],x[3]]).T        \n",
    "                print('Run '+str(count+1)+' out of '+str(len_total))\n",
    "                count = count+1\n",
    "                \n",
    "max_ind = np.argmax(test_acc)\n",
    "print('Max Accuracy = '+str(test_acc[max_ind,0]*100)+'%')\n",
    "print('with L = '+str(params[max_ind,0])+', Bsize = '+str(params[max_ind,1])+', L2 = '+str(params[max_ind,2])+', N = '+str(params[max_ind,3]))\n",
    "\n",
    "## Plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X1 = params[:,0]\n",
    "X2 = params[:,1]\n",
    "X3 = params[:,2]\n",
    "X4 = params[:,3]\n",
    "Y = test_acc\n",
    "\n",
    "plt.plot(X1,Y,marker='o',linestyle='None',markersize=12)\n",
    "plt.title('Test Accuracy vs NN Length')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.xlabel('NN Length')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(X2,Y,marker='o',linestyle='None',markersize=12)\n",
    "plt.title('Test Accuracy vs Batch Size')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(X3,Y,marker='o',linestyle='None',markersize=12)\n",
    "plt.title('Test Accuracy vs L2 Lambda')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.xlabel('Lambda')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(X4,Y,marker='o',linestyle='None',markersize=12)\n",
    "plt.title('Test Accuracy vs Nodes/Layer')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.xlabel('Nodes/Layer')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "ProjectCodeIDK.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
